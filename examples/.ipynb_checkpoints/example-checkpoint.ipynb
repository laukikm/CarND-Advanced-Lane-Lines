{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) #These are coordinates of chessboard corners in the real frame\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None) #These are the pixel coordinates of the corners\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_size=img.shape\n",
    "\n",
    "#The calibration and distortion matrices\n",
    "ret,cameraMatrix,distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img.shape[::-1][2],img.shape[::-1][1]), None, None)\n",
    "\n",
    "#Correct for distortions\n",
    "#for fname in images:\n",
    "    #src=cv2.imread(fname)\n",
    "    #src=cv2.undistort(src, cameraMatrix, distCoeffs)\n",
    "    #cv2.imshow('img',src)\n",
    "    #cv2.waitKey(500)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_directory = glob.glob('../test_images/test*.jpg')\n",
    "save_images_directory='../output_images/'\n",
    "test_images=[cv2.imread(img_name) for img_name in test_images_directory]\n",
    "\n",
    "for image_no,image in enumerate(test_images):\n",
    "    \n",
    "    image=cv2.undistort(image,cameraMatrix,distCoeffs)\n",
    "    image=cv2.GaussianBlur(image,(9,9),0)\n",
    "    #image=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=-1)\n",
    "    \n",
    "    hls_img=cv2.cvtColor(image,cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    #hls_img=cv2.GaussianBlur(hls_img,(9,9),0)\n",
    "    hls_img_grad=cv2.Sobel(hls_img,cv2.CV_64F,1,0,ksize=-1)\n",
    "    s_img=hls_img[:,:,1]\n",
    "    s_img=cv2.adaptiveThreshold(s_img,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,3,-1)\n",
    "\n",
    "    intensities=[hls_img[i][j][2] for i,j in zip(range(len(image)),range(len(image[0])))]\n",
    "    threshold=1.3*np.mean(intensities)\n",
    "    \n",
    "    hsv_img=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    hsv_img=cv2.Sobel(hsv_img,cv2.CV_64F,1,0,ksize=-1)#+cv2.Sobel(hsv_img,cv2.CV_64F,1,0,ksize=-1)\n",
    "    \n",
    "    canny_img=cv2.Canny(image,120,20,-1)\n",
    "    l_values=[hsv_img[i][j][0] for i,j in zip(range(len(image)),range(len(image[0])))]\n",
    "    l_threshold=180\n",
    "    \n",
    "    lab_img=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "    sat_img=hls_img[:,:,2]\n",
    "    gray_img=hls_img[:,:,1]\n",
    "        \n",
    "    #ret,threshold_hls=cv2.threshold(hls_img,180,200,type=0)\n",
    "    #ret,hsv_img=cv2.threshold(hsv_img[:,:,0],20,100,type=1)\n",
    "    \n",
    "    #ret,binary_image=cv2.threshold(sat_img,threshold,200,type=0)\n",
    "    binary_img=cv2.adaptiveThreshold(lab_img[:,:,2],200,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,5,-1)\n",
    "    \n",
    "    #binary_image=cv2.blur(binary_image,(19,19),0)\n",
    "\n",
    "    \n",
    "    ret,binary_image2=cv2.threshold(gray_img,l_threshold,100,type=0)\n",
    "    \n",
    "    cv2.imwrite(save_images_directory+'test'+str(image_no+1)+'.jpg',cv2.bitwise_or(binary_img,s_img))\n",
    "    \n",
    "    cv2.imwrite(save_images_directory+'canny/''test'+str(image_no+1)+'.jpg',canny_img)\n",
    "    cv2.imshow('image',canny_img)\n",
    "    cv2.waitKey(2000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Create Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_warp_points(img_height,img_width,x_center_adj=0):\n",
    "    \n",
    "    # calculator the vertices of the region of interest\n",
    "    imshape = (img_height, img_width)\n",
    "    xcenter=imshape[1]/2+x_center_adj\n",
    "#     xfd=55\n",
    "#     yf=450\n",
    "#     xoffset=100\n",
    "    xfd=54\n",
    "    yf=450\n",
    "    xoffset=120\n",
    "    \n",
    "    src = np.float32(\n",
    "        [(xoffset,imshape[0]),\n",
    "         (xcenter-xfd, yf), \n",
    "         (xcenter+xfd,yf), \n",
    "         (imshape[1]-xoffset,imshape[0])])\n",
    "    \n",
    "    dst = np.float32(\n",
    "        [(xoffset,imshape[1]),\n",
    "         (xoffset,0),\n",
    "         (imshape[0]-xoffset, 0),\n",
    "        (imshape[0]-xoffset,imshape[1])])\n",
    "        \n",
    "    return src, dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I looked at the image 'Straight Lines 1', and found that near the bottom of the image, the lane width is 705 pixels.\n",
    "#This could be used to get the height of the camera from the road\n",
    "\n",
    "#This is simply image distortion such that the source points fit the destination points\n",
    "\n",
    "\n",
    "st_lines_img=cv2.imread('../test_images/straight_lines1.jpg')\n",
    "\n",
    "img_pts=np.float32(\n",
    "                    [[181,719], #Bottom Left\n",
    "                    [1104,719], #Bottom Right\n",
    "                    [651,430], #Top Right\n",
    "                    [631,430]] #Top Left\n",
    "                  ) \n",
    "width=1104-181\n",
    "height=719-430\n",
    "\n",
    "\n",
    "for pt in img_pts:\n",
    "    cv2.circle(st_lines_img,tuple(pt),1,(255,0,0),10)\n",
    "\n",
    "#cv2.imshow('st_lines',st_lines_img)\n",
    "#cv2.waitKey(2000)\n",
    "\n",
    "#ground_pts=np.float32([[0,0],[0,3.6576],[24.384,3.6576],[24.384,0]]) #It seems that the ground points also need to be in pixels\n",
    "\n",
    "ground_pts=np.float32(\n",
    "                       [[0,width-1], #Bottom Left\n",
    "                       [height-1,width-1], #Bottom Right\n",
    "                       [height-1,0], #Top Right\n",
    "                       [0,0]] #Top Left\n",
    "                     ) \n",
    "\n",
    "img_pts,ground_pts=calc_warp_points(720,1280)\n",
    "\n",
    "M=cv2.getPerspectiveTransform(img_pts,ground_pts) #M will stay the same for all images\n",
    "\n",
    "dst=cv2.warpPerspective(st_lines_img,M,(720,1280),flags=cv2.INTER_LINEAR)\n",
    "#cv2.imshow('st_lines',dst)\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "binary_images_directory=glob.glob('../output_images/test*.jpg')\n",
    "canny_images_directory=glob.glob('../output_images/canny/test*.jpg')\n",
    "\n",
    "binary_images=[cv2.imread(img_name) for img_name in binary_images_directory]\n",
    "canny_images=[cv2.imread(img_name) for img_name in canny_images_directory]\n",
    "\n",
    "warped_images_directory='../output_images/warped/'\n",
    "warped_canny_images_directory='../output_images/warped/canny/'\n",
    "\n",
    "for image_no,image in enumerate(binary_images):\n",
    "    dst=cv2.warpPerspective(image,M,(720,1280))\n",
    "    \n",
    "    canny_image=canny_images[image_no]\n",
    "    dst_canny=cv2.warpPerspective(canny_image,M,(720,1280))\n",
    "    #cv2.imshow('img',dst)\n",
    "    cv2.imwrite(warped_images_directory+'test'+str(image_no+1)+'.jpg',dst)\n",
    "    cv2.imwrite(warped_canny_images_directory+'test'+str(image_no+1)+'.jpg',dst_canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Lane Pixels in Warped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the peak of the histogram of white pixels in the bottom half of the image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def histogram(image,top=800,bottom=1250):\n",
    "    #image is assumed to be binary\n",
    "    window_start=0\n",
    "    values=np.sum(image[top:bottom][:],axis=0)\n",
    "    #print(image[top:bottom][:])\n",
    "    return np.sum(values,axis=1)/3/1000\n",
    "\n",
    "def get_peaks(values,tolerance=5):\n",
    "    peaks=[]\n",
    "    midpoint=int(len(values)/2)\n",
    "    \n",
    "    peaks.append(np.argmax(values[0:midpoint]))\n",
    "    peaks.append(midpoint+np.argmax(values[midpoint:]))\n",
    "    \n",
    "    return peaks #these are pixels\n",
    "\n",
    "def get_points_for_interpolation(image,window_width=30,window_height=60):\n",
    "    left_lane=[]\n",
    "    right_lane=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box:\n",
    "    def __init__(self,image,center_x=30,bottom_y=1250,box_height=120,box_width=120):\n",
    "        self.image=image\n",
    "        \n",
    "        self.bottom_y=bottom_y+box_height\n",
    "        self.center_x=center_x\n",
    "        self.box_width=box_width\n",
    "        self.box_height=box_height\n",
    "        \n",
    "        self.update_coords(self.center_x)\n",
    "        self.points=[]\n",
    "        \n",
    "    #Working Fine\n",
    "    def get_mean_x(self):\n",
    "        x_values=[]\n",
    "        for y in range(self.top_y,self.bottom_y):\n",
    "            for x in range(int(self.left),int(self.right)):\n",
    "                if np.sum(self.image[y][x])>0:\n",
    "                    x_values.append(x)\n",
    "                    #self.image[y][x]=[120,120,120]\n",
    "        #print('mean calculated',np.mean(x_values))\n",
    "        if len(x_values)>0:\n",
    "            return np.mean(x_values)\n",
    "        return self.center_x\n",
    "    \n",
    "    def update_coords(self,center_x):\n",
    "        self.bottom_y-=int(self.box_height)\n",
    "        self.left=max(int(center_x-(self.box_width/2)),0)\n",
    "        self.top_y=max(int(self.bottom_y-self.box_height),0)\n",
    "        self.right=min(self.image.shape[1]-1,int(center_x+self.box_width/2))\n",
    "        \n",
    "        self.center_x=center_x\n",
    "    \n",
    "    def update_points(self):\n",
    "        y=self.bottom_y-int(self.box_height/2)\n",
    "        x=self.get_mean_x()\n",
    "        \n",
    "        self.points.append((x,y))\n",
    "        self.update_coords(x)\n",
    "    \n",
    "    def get_corners(self):\n",
    "        return [(self.left,self.top_y),(self.right,self.bottom_y)]\n",
    "    \n",
    "\n",
    "class LaneDetector:\n",
    "    def __init__(self,image,box_width=100,box_height=120):\n",
    "        self.image=image\n",
    "        values=histogram(image)\n",
    "        self.peaks=get_peaks(values)\n",
    "        \n",
    "        self.box_width=box_width\n",
    "        self.box_height=box_height\n",
    "    \n",
    "        left_box=Box(image,center_x=self.peaks[0],bottom_y=1250,box_height=box_height,box_width=box_width)\n",
    "        right_box=Box(image,center_x=self.peaks[1],bottom_y=1250,box_height=box_height,box_width=box_width)\n",
    "        self.boxes=[left_box,right_box]\n",
    "                \n",
    "        self.left_points=[]\n",
    "        self.right_points=[]\n",
    "        self.points=[self.left_points,self.right_points]\n",
    "\n",
    "        self.box_locations=[[],[]]\n",
    "        self.polynomial_coeffs=[[],[]]\n",
    "        \n",
    "    def update_points(self):\n",
    "        while(self.boxes[0].bottom_y>0 and self.boxes[1].bottom_y>0):\n",
    "            for i,box in enumerate(self.boxes):\n",
    "                self.box_locations[i].append(box.get_corners())\n",
    "                box.update_points()\n",
    "        \n",
    "        self.left_points=self.boxes[0].points\n",
    "        self.right_points=self.boxes[1].points\n",
    "        \n",
    "    def draw_rectangles(self):\n",
    "        for i in range(len(self.box_locations[0])):\n",
    "            left_corners=self.box_locations[0][i]\n",
    "            right_corners=self.box_locations[1][i]\n",
    "            \n",
    "            cv2.rectangle(self.image,left_corners[0],left_corners[1],(255,0,0),1)\n",
    "            cv2.rectangle(self.image,right_corners[0],right_corners[1],(0,0,255),1)   \n",
    "    \n",
    "    def fit_points(self):\n",
    "        for i,box in enumerate(self.boxes):\n",
    "            interp_points=box.points #Make a copy\n",
    "            x=[]\n",
    "            y=[]\n",
    "            for point in interp_points: \n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "            self.polynomial_coeffs[i]=np.polyfit(y,x,3) #Choosing cubic polynomials\n",
    "            \n",
    "    def evaluate_polynomial_at(self,y,i):\n",
    "        coeffs=self.polynomial_coeffs[i]\n",
    "        return np.polyval(coeffs,y)\n",
    "    \n",
    "    def draw_lines(self):\n",
    "        for y in range(0,1250,2):\n",
    "            left_x=int(self.evaluate_polynomial_at(y,0))\n",
    "            right_x=int(self.evaluate_polynomial_at(y,1))\n",
    "            self.image[y][left_x]=[255,0,255]\n",
    "            self.image[y][right_x]=[0,255,0]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_images_directory=glob.glob('../output_images/warped/test*.jpg')\n",
    "warped_images=[cv2.imread(img_name) for img_name in warped_images_directory]\n",
    "\n",
    "warped_images_binary=[cv2.threshold(image,150,255,type=0)[1] for image in warped_images]\n",
    "window_width=50\n",
    "\n",
    "lane_detectors=[]\n",
    "for image in warped_images_binary: \n",
    "    lane_detector=LaneDetector(image)\n",
    "    lane_detector.update_points()\n",
    "    lane_detector.draw_rectangles()\n",
    "    lane_detector.fit_points()\n",
    "    lane_detector.draw_lines()\n",
    "    \n",
    "    #cv2.imshow('img',lane_detector.image)\n",
    "    #cv2.waitKey(2000)\n",
    "    lane_detectors.append(lane_detector)\n",
    "    \n",
    "    #cv2.imshow('img',lane_detector.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3]\n",
    "b=[2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (3, 4)]"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((zip(a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
