{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) #These are coordinates of chessboard corners in the real frame\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None) #These are the pixel coordinates of the corners\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_size=img.shape\n",
    "\n",
    "#The calibration and distortion matrices\n",
    "ret,cameraMatrix,distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img.shape[::-1][2],img.shape[::-1][1]), None, None)\n",
    "\n",
    "#Correct for distortions\n",
    "#for fname in images:\n",
    "    #src=cv2.imread(fname)\n",
    "    #src=cv2.undistort(src, cameraMatrix, distCoeffs)\n",
    "    #cv2.imshow('img',src)\n",
    "    #cv2.waitKey(500)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_image(image,cameraMatrix,distCoeffs):\n",
    "    image=cv2.undistort(image,cameraMatrix,distCoeffs)\n",
    "    image=cv2.GaussianBlur(image,(9,9),0)\n",
    "    #image=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=-1)\n",
    "    \n",
    "    hls_img=cv2.cvtColor(image,cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    #hls_img=cv2.GaussianBlur(hls_img,(9,9),0)\n",
    "    hls_img_grad=cv2.Sobel(hls_img,cv2.CV_64F,1,0,ksize=-1)\n",
    "    s_img=hls_img[:,:,1]\n",
    "    s_img=cv2.adaptiveThreshold(s_img,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,3,-1)\n",
    "\n",
    "    #intensities=[hls_img[i][j][2] for i,j in zip(range(len(image)),range(len(image[0])))]\n",
    "    #threshold=1.3*np.mean(intensities)\n",
    "    \n",
    "    #hsv_img=cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    #hsv_img=cv2.Sobel(hsv_img,cv2.CV_64F,1,0,ksize=-1)#+cv2.Sobel(hsv_img,cv2.CV_64F,1,0,ksize=-1)\n",
    "    \n",
    "    #canny_img=cv2.Canny(image,120,20,-1)\n",
    "    #l_values=[hsv_img[i][j][0] for i,j in zip(range(len(image)),range(len(image[0])))]\n",
    "    #l_threshold=180\n",
    "    \n",
    "    lab_img=cv2.cvtColor(image,cv2.COLOR_BGR2LAB)\n",
    "    #sat_img=hls_img[:,:,2]\n",
    "    #gray_img=hls_img[:,:,1]\n",
    "        \n",
    "    #ret,threshold_hls=cv2.threshold(hls_img,180,200,type=0)\n",
    "    #ret,hsv_img=cv2.threshold(hsv_img[:,:,0],20,100,type=1)\n",
    "    \n",
    "    #ret,binary_image=cv2.threshold(sat_img,threshold,200,type=0)\n",
    "    binary_img=cv2.adaptiveThreshold(lab_img[:,:,2],200,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,5,-1)\n",
    "    \n",
    "    #binary_image=cv2.blur(binary_image,(19,19),0)\n",
    "\n",
    "    \n",
    "    #ret,binary_image2=cv2.threshold(gray_img,l_threshold,100,type=0)\n",
    "    \n",
    "    return cv2.bitwise_or(binary_img,s_img)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'canny_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-34b27e5680bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbinary_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_binary_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistCoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_images_directory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbinary_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_images_directory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'canny/'\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcanny_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcanny_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'canny_img' is not defined"
     ]
    }
   ],
   "source": [
    "test_images_directory = glob.glob('../test_images/test*.jpg')\n",
    "save_images_directory='../output_images/'\n",
    "test_images=[cv2.imread(img_name) for img_name in test_images_directory]\n",
    "\n",
    "for image_no,image in enumerate(test_images):\n",
    "    \n",
    "    binary_image=get_binary_image(image,cameraMatrix,distCoeffs)\n",
    "    cv2.imwrite(save_images_directory+'test'+str(image_no+1)+'.jpg',binary_image)\n",
    "    cv2.imwrite(save_images_directory+'canny/''test'+str(image_no+1)+'.jpg',canny_img)\n",
    "    cv2.imshow('image',canny_img)\n",
    "    cv2.waitKey(20)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWarper:\n",
    "    def __init__(self):\n",
    "        self.calc_warp_points(720,1280)\n",
    "        self.get_transforms()\n",
    "        \n",
    "    def calc_warp_points(self,img_height,img_width,x_center_adj=0):\n",
    "\n",
    "        # calculator the vertices of the region of interest\n",
    "        imshape = (img_height, img_width)\n",
    "        xcenter=imshape[1]/2+x_center_adj\n",
    "    #     xfd=55\n",
    "    #     yf=450\n",
    "    #     xoffset=100\n",
    "        xfd=54\n",
    "        yf=450\n",
    "        xoffset=120\n",
    "\n",
    "        src = np.float32(\n",
    "            [(xoffset,imshape[0]),\n",
    "             (xcenter-xfd, yf), \n",
    "             (xcenter+xfd,yf), \n",
    "             (imshape[1]-xoffset,imshape[0])])\n",
    "\n",
    "        dst = np.float32(\n",
    "            [(xoffset,imshape[1]),\n",
    "             (xoffset,0),\n",
    "             (imshape[0]-xoffset, 0),\n",
    "            (imshape[0]-xoffset,imshape[1])])\n",
    "\n",
    "        self.src=src\n",
    "        self.dst=dst\n",
    "\n",
    "    def get_transforms(self):\n",
    "        self.M=cv2.getPerspectiveTransform(self.src,self.dst) #M will stay the same for all images\n",
    "        self.M_inv=cv2.getPerspectiveTransform(self.dst,self.src) #M_inv will stay the same for all images\n",
    "    \n",
    "    def warp_image(self,image):\n",
    "        return cv2.warpPerspective(image,self.M,(720,1280),flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def unwarp_image(self,image):\n",
    "        return cv2.warpPerspective(image,self.M_inv,(1280,720),flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I looked at the image 'Straight Lines 1', and found that near the bottom of the image, the lane width is 705 pixels.\n",
    "#This could be used to get the height of the camera from the road\n",
    "\n",
    "#This is simply image distortion such that the source points fit the destination points\n",
    "\n",
    "\n",
    "st_lines_img=cv2.imread('../test_images/straight_lines1.jpg')\n",
    "\n",
    "#for pt in img_pts:\n",
    "#    cv2.circle(st_lines_img,tuple(pt),1,(255,0,0),10)\n",
    "\n",
    "#cv2.imshow('st_lines',st_lines_img)\n",
    "#cv2.waitKey(2000)\n",
    "\n",
    "#ground_pts=np.float32([[0,0],[0,3.6576],[24.384,3.6576],[24.384,0]]) #It seems that the ground points also need to be in pixels\n",
    "\n",
    "warper=ImageWarper()\n",
    "\n",
    "dst=warper.warp_image(st_lines_img)\n",
    "cv2.imshow('st_lines',dst)\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "binary_images_directory=glob.glob('../output_images/test*.jpg')\n",
    "canny_images_directory=glob.glob('../output_images/canny/test*.jpg')\n",
    "\n",
    "binary_images=[cv2.imread(img_name) for img_name in binary_images_directory]\n",
    "canny_images=[cv2.imread(img_name) for img_name in canny_images_directory]\n",
    "\n",
    "warped_images_directory='../output_images/warped/'\n",
    "warped_canny_images_directory='../output_images/warped/canny/'\n",
    "\n",
    "for image_no,image in enumerate(binary_images):\n",
    "    dst=warper.warp_image(image)\n",
    "    \n",
    "    canny_image=canny_images[image_no]\n",
    "    dst_canny=warper.warp_image(canny_image)\n",
    "    #cv2.imshow('img',dst)\n",
    "    cv2.imwrite(warped_images_directory+'test'+str(image_no+1)+'.jpg',dst)\n",
    "    cv2.imwrite(warped_canny_images_directory+'test'+str(image_no+1)+'.jpg',dst_canny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Lane Pixels in Warped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the peak of the histogram of white pixels in the bottom half of the image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def histogram(image,top=800,bottom=1250):\n",
    "    #image is assumed to be binary\n",
    "    window_start=0\n",
    "    values=np.sum(image[top:bottom][:],axis=0)\n",
    "    #print(values)\n",
    "    return np.sum(values,axis=1)/3/1000\n",
    "\n",
    "def get_peaks(values,tolerance=5):\n",
    "    peaks=[]\n",
    "    midpoint=int(len(values)/2)\n",
    "    \n",
    "    peaks.append(np.argmax(values[0:midpoint]))\n",
    "    peaks.append(midpoint+np.argmax(values[midpoint:]))\n",
    "    \n",
    "    return peaks #these are pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box:\n",
    "    def __init__(self,image,center_x=30,bottom_y=1250,box_height=120,box_width=120,threshold=0):\n",
    "        self.image=image\n",
    "        \n",
    "        self.bottom_y=bottom_y+box_height\n",
    "        self.center_x=center_x\n",
    "        self.box_width=box_width\n",
    "        self.box_height=box_height\n",
    "        \n",
    "        self.update_coords(self.center_x)\n",
    "        self.points=[]\n",
    "        self.threshold=threshold\n",
    "        \n",
    "        self.cutoff=500\n",
    "        \n",
    "    #Working Fine\n",
    "    def get_mean_x(self):\n",
    "        x_values=0\n",
    "        n_occurences=0\n",
    "        n_iterations=0\n",
    "        for y in range(self.top_y,self.bottom_y):\n",
    "            if(n_occurences>self.threshold or n_iterations>self.cutoff):\n",
    "                break\n",
    "            for x in range(int(self.left),int(self.right)):\n",
    "                n_iterations+=1\n",
    "                if np.sum(self.image[y][x])>0:\n",
    "                    x_values+=x\n",
    "                    n_occurences+=1\n",
    "                    if n_occurences>self.threshold:\n",
    "                        break\n",
    "        \n",
    "        if n_occurences>0:\n",
    "            return x_values/n_occurences\n",
    "        return self.center_x\n",
    "    \n",
    "    def update_coords(self,center_x):\n",
    "        self.bottom_y-=int(self.box_height)\n",
    "        self.left=max(int(center_x-(self.box_width/2)),0)\n",
    "        self.top_y=max(int(self.bottom_y-self.box_height),0)\n",
    "        self.right=min(self.image.shape[1]-1,int(center_x+self.box_width/2))\n",
    "        \n",
    "        self.center_x=center_x\n",
    "    \n",
    "    def update_points(self):\n",
    "        y=self.bottom_y-int(self.box_height/2)\n",
    "        x=self.get_mean_x()\n",
    "        \n",
    "        self.points.append((x,y))\n",
    "        self.update_coords(x)\n",
    "    \n",
    "    def get_corners(self):\n",
    "        return [(self.left,self.top_y),(self.right,self.bottom_y)]\n",
    "    \n",
    "\n",
    "class LaneDetector:\n",
    "    def __init__(self,image,box_width=30,box_height=50,threshold=0):\n",
    "        self.image=image\n",
    "        values=histogram(image)\n",
    "        self.peaks=get_peaks(values)\n",
    "        \n",
    "        self.box_width=box_width\n",
    "        self.box_height=box_height\n",
    "    \n",
    "        left_box=Box(image,center_x=self.peaks[0],bottom_y=1250,box_height=box_height,box_width=box_width,threshold=threshold)\n",
    "        right_box=Box(image,center_x=self.peaks[1],bottom_y=1250,box_height=box_height,box_width=box_width,threshold=threshold)\n",
    "        self.boxes=[left_box,right_box]\n",
    "                \n",
    "        self.left_points=[]\n",
    "        self.right_points=[]\n",
    "        self.points=[self.left_points,self.right_points]\n",
    "\n",
    "        self.box_locations=[[],[]]\n",
    "        self.polynomial_coeffs=[[],[]]\n",
    "        \n",
    "    def update_points(self):\n",
    "        while(self.boxes[0].top_y>0 and self.boxes[1].top_y>0):\n",
    "            for i,box in enumerate(self.boxes):\n",
    "                self.box_locations[i].append(box.get_corners())\n",
    "                box.update_points()\n",
    "        \n",
    "        self.left_points=self.boxes[0].points\n",
    "        self.right_points=self.boxes[1].points\n",
    "        \n",
    "    def draw_rectangles(self):\n",
    "        \n",
    "        for i in range(len(self.box_locations[0])):\n",
    "            left_corners=self.box_locations[0][i]\n",
    "            right_corners=self.box_locations[1][i]\n",
    "            \n",
    "            cv2.rectangle(self.image,left_corners[0],left_corners[1],(255,0,0),1)\n",
    "            cv2.rectangle(self.image,right_corners[0],right_corners[1],(0,0,255),1)   \n",
    "    \n",
    "    def fit_points(self):\n",
    "        self.update_points()\n",
    "        for i,box in enumerate(self.boxes):\n",
    "            interp_points=box.points \n",
    "            x=[]\n",
    "            y=[]\n",
    "            for point in interp_points:  #O(img_height/box_height)\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "            self.polynomial_coeffs[i]=np.polyfit(y,x,3) #Choosing cubic polynomials \n",
    "            \n",
    "    def evaluate_polynomial_at(self,y,i):\n",
    "        coeffs=self.polynomial_coeffs[i]\n",
    "        return np.polyval(coeffs,y)\n",
    "    \n",
    "    def constrain(self,value,min_val,max_val):\n",
    "        value=min(value,max_val)\n",
    "        value=max(min_val,value)\n",
    "        return value\n",
    "    \n",
    "    def draw_lines(self,image=None):\n",
    "        if image is None:\n",
    "            image=self.image\n",
    "        for y in range(0,1250,2):\n",
    "            left_x=int(self.evaluate_polynomial_at(y,0))\n",
    "            right_x=int(self.evaluate_polynomial_at(y,1))\n",
    "            \n",
    "            left_x=self.constrain(left_x,0,719)\n",
    "            right_x=self.constrain(right_x,0,719)\n",
    "            \n",
    "            image[y][left_x]=[255,0,255]\n",
    "            image[y][right_x]=[0,255,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_images_directory=glob.glob('../output_images/warped/test*.jpg')\n",
    "warped_images=[cv2.imread(img_name) for img_name in warped_images_directory]\n",
    "\n",
    "warped_images_binary=[cv2.threshold(image,150,255,type=0)[1] for image in warped_images]\n",
    "window_width=50\n",
    "\n",
    "lane_detectors=[]\n",
    "warper=ImageWarper()\n",
    "for image in warped_images_binary: \n",
    "    lane_detector=LaneDetector(image)\n",
    "    lane_detector.update_points()\n",
    "    lane_detector.draw_rectangles()\n",
    "    lane_detector.fit_points()\n",
    "    lane_detector.draw_lines()\n",
    "    \n",
    "    cv2.imshow('img',lane_detector.image)\n",
    "    cv2.waitKey(2000)\n",
    "    lane_detectors.append(lane_detector)\n",
    "    \n",
    "    #cv2.imshow('img',lane_detector.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-20edb6f1ef43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLaneDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped_color_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-f7b0543aa2f1>\u001b[0m in \u001b[0;36mdraw_lines\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mleft_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_polynomial_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mright_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_polynomial_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mleft_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m719\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-f7b0543aa2f1>\u001b[0m in \u001b[0;36mevaluate_polynomial_at\u001b[0;34m(self, y, i)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_polynomial_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mcoeffs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolynomial_coeffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolyval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoeffs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconstrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpolyval\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/polynomial.py\u001b[0m in \u001b[0;36mpolyval\u001b[0;34m(p, x)\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('../project_video.mp4')\n",
    "warper=ImageWarper()\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    binary_image = get_binary_image(frame,cameraMatrix,distCoeffs) #This one's undistorted\n",
    "    binary_image=cv2.merge([binary_image]*3) #This converts a one channel image into a 3 channel image\n",
    "    \n",
    "    warped_image=warper.warp_image(binary_image)\n",
    "    warped_color_image=warper.warp_image(frame)\n",
    "    ret,warped_image=cv2.threshold(warped_image,150,255,type=0)\n",
    "    \n",
    "    lane_detector=LaneDetector(warped_image)\n",
    "    lane_detector.fit_points()\n",
    "    lane_detector.draw_lines(warped_color_image)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    unwarped_color_image=warper.unwarp_image(warped_color_image)\n",
    "    cv2.imshow('frame',unwarped_color_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warped_image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
