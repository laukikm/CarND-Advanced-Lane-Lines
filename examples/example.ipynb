{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) #These are coordinates of chessboard corners in the real frame\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None) #These are the pixel coordinates of the corners\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #cv2.imshow('img',img)\n",
    "        #cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_size=img.shape\n",
    "\n",
    "#The calibration and distortion matrices\n",
    "ret,cameraMatrix,distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img.shape[::-1][2],img.shape[::-1][1]), None, None)\n",
    "\n",
    "#Correct for distortions\n",
    "#for fname in images:\n",
    "    #src=cv2.imread(fname)\n",
    "    #src=cv2.undistort(src, cameraMatrix, distCoeffs)\n",
    "    #cv2.imshow('img',src)\n",
    "    #cv2.waitKey(500)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_gradient(image,dx,dy):\n",
    "    img_grad=cv2.Sobel(image,cv2.CV_64F,dx,dy,ksize=-1)\n",
    "    img_grad=np.abs(img_grad)\n",
    "    return np.uint8(img_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_image(image,cameraMatrix,distCoeffs):\n",
    "    image=cv2.undistort(image,cameraMatrix,distCoeffs)\n",
    "    image=cv2.GaussianBlur(image,(9,9),0)\n",
    "    #image=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=-1)\n",
    "    \n",
    "    hls_img=cv2.cvtColor(image,cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    #hls_img=cv2.GaussianBlur(hls_img,(9,9),0)\n",
    "    hls_img_grad=get_abs_gradient(hls_img,1,0)\n",
    "    s_img=hls_img[:,:,2]\n",
    "    s_img=cv2.adaptiveThreshold(s_img,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,3,-1) #This is to detect yellow\n",
    "    \n",
    "    binary_img=cv2.adaptiveThreshold(hls_img[:,:,2],200,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,5,-1) #This is to detect yellow lines\n",
    "    \n",
    "\n",
    "    ret,white_threshold=cv2.threshold(hls_img[:,:,1],150,100,type=0)\n",
    "    ret,grad_threshold=cv2.threshold(hls_img_grad[:,:,1],150,100,type=0)\n",
    "    \n",
    "    ret,sat_grad_threshold=cv2.threshold(hls_img_grad[:,:,2],150,100,type=0)\n",
    "    \n",
    "    lum_cutoff=cv2.bitwise_and(grad_threshold,white_threshold)\n",
    "    gradient_image=cv2.bitwise_or(lum_cutoff,sat_grad_threshold)\n",
    "    \n",
    "    \n",
    "    return gradient_image\n",
    "    return cv2.bitwise_or(gradient_image,s_img)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_image2(image,cameraMatrix,distCoeffs):\n",
    "    image=cv2.undistort(image,cameraMatrix,distCoeffs)\n",
    "    image=cv2.GaussianBlur(image,(9,9),10)\n",
    "    #image=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=-1)\n",
    "    \n",
    "    hls_img=cv2.cvtColor(image,cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    #hls_img=cv2.GaussianBlur(hls_img,(9,9),0)\n",
    "    hls_img_grad=cv2.Sobel(hls_img,cv2.CV_64F,1,0,ksize=-1)\n",
    "    s_img=hls_img[:,:,2]\n",
    "    s_img=cv2.adaptiveThreshold(s_img,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "           cv2.THRESH_BINARY,5,0)\n",
    "    \n",
    "    #s_img=cv2.adaptiveThreshold(s_img,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    #       cv2.THRESH_BINARY,3,-5)\n",
    "    \n",
    "    yellow_hsv_low  = np.array([ 120, 0, 12])\n",
    "    yellow_hsv_high = np.array([ 180, 255, 30])\n",
    "    hue_img=hls_img[:,:,2]\n",
    "    hue_img=cv2.inRange(hls_img,yellow_hsv_low,yellow_hsv_high)\n",
    "    \n",
    "    \n",
    "    \n",
    "    lab_img=cv2.cvtColor(image,cv2.COLOR_BGR2LAB) #The LAB channel is useless for yellow detection in this case\n",
    "    binary_img=cv2.adaptiveThreshold(hls_img[:,:,1],200,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,5,-1)\n",
    "    \n",
    "    sat_image_blurred=cv2.GaussianBlur(hls_img[:,:,2],(11,11),10)\n",
    "    lum_image_blurred=cv2.GaussianBlur(hls_img[:,:,1],(11,11),10)\n",
    "    for i in range(0):\n",
    "        sat_image_blurred=cv2.GaussianBlur(sat_image_blurred,(19,19),10)\n",
    "    \n",
    "    sobel_x=cv2.Sobel(sat_image_blurred,cv2.CV_64F,1,0,ksize=-1)\n",
    "    sobel_x=np.abs(sobel_x)\n",
    "    sobel_x=np.uint8(sobel_x)\n",
    "    \n",
    "    sobel_l=cv2.Sobel(lum_image_blurred,cv2.CV_64F,1,0,ksize=3)\n",
    "    sobel_l=np.abs(sobel_l)\n",
    "    sobel_l=np.uint8(sobel_l)\n",
    "    \n",
    "    ret,sobel_x=cv2.threshold(sobel_x,60,200,cv2.THRESH_BINARY)\n",
    "    #ret,sobel_l=cv2.threshold(sobel_l,60,200,cv2.THRESH_BINARY)\n",
    "    #sobel_x=cv2.adaptiveThreshold(sobel_x,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    #       cv2.THRESH_BINARY,3,-5)\n",
    "    \n",
    "    \n",
    "    scaled_sobel=np.uint8(255*sobel_x/np.max(sobel_x))\n",
    "    \n",
    "    laplacian=cv2.Laplacian(hls_img[:,:,2],cv2.CV_64F)\n",
    "    laplacian=np.abs(laplacian)\n",
    "    laplacian=np.uint8(laplacian)\n",
    "    \n",
    "    canny_img=cv2.Canny(sobel_x,60,190,-1)\n",
    "    \n",
    "    return s_img\n",
    "    return cv2.bitwise_or(binary_img,sobel_l,sobel_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 873)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_image=cv2.imread('../challenging_image.png')\n",
    "challenge_binary=get_binary_image(challenge_image,cameraMatrix,distCoeffs)\n",
    "\n",
    "challenge_binary=np.uint8(challenge_binary)\n",
    "cv2.imshow('challenge_binary',challenge_binary)\n",
    "\n",
    "#np.unique(challenge_binary)\n",
    "challenge_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_directory = glob.glob('../test_images/test*.jpg')\n",
    "save_images_directory='../output_images/'\n",
    "test_images=[cv2.imread(img_name) for img_name in test_images_directory]\n",
    "\n",
    "for image_no,image in enumerate(test_images):\n",
    "    \n",
    "    binary_image=get_binary_image(image,cameraMatrix,distCoeffs)\n",
    "    cv2.imwrite(save_images_directory+'test'+str(image_no+1)+'.jpg',binary_image)\n",
    "    #cv2.imwrite(save_images_directory+'canny/''test'+str(image_no+1)+'.jpg',canny_img)\n",
    "    #cv2.imshow('image',canny_img)\n",
    "    cv2.waitKey(20)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWarper:\n",
    "    def __init__(self):\n",
    "        self.calc_warp_points(720,1280)\n",
    "        self.get_transforms()\n",
    "        \n",
    "    def calc_warp_points(self,img_height,img_width,x_center_adj=0):\n",
    "\n",
    "        # calculator the vertices of the region of interest\n",
    "        imshape = (img_height, img_width)\n",
    "        xcenter=imshape[1]/2+x_center_adj\n",
    "    #     xfd=55\n",
    "    #     yf=450\n",
    "    #     xoffset=100\n",
    "        xfd=54\n",
    "        yf=450\n",
    "        xoffset=120\n",
    "\n",
    "        src = np.float32(\n",
    "            [(xoffset,imshape[0]),\n",
    "             (xcenter-xfd, yf), \n",
    "             (xcenter+xfd,yf), \n",
    "             (imshape[1]-xoffset,imshape[0])])\n",
    "\n",
    "        dst = np.float32(\n",
    "            [(xoffset,imshape[1]),\n",
    "             (xoffset,0),\n",
    "             (imshape[0]-xoffset, 0),\n",
    "            (imshape[0]-xoffset,imshape[1])])\n",
    "\n",
    "        self.src=src\n",
    "        self.dst=dst\n",
    "\n",
    "    def get_transforms(self):\n",
    "        self.M=cv2.getPerspectiveTransform(self.src,self.dst) #M will stay the same for all images\n",
    "        self.M_inv=cv2.getPerspectiveTransform(self.dst,self.src) #M_inv will stay the same for all images\n",
    "    \n",
    "    def warp_image(self,image):\n",
    "        return cv2.warpPerspective(image,self.M,(720,1280),flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def unwarp_image(self,image):\n",
    "        return cv2.warpPerspective(image,self.M_inv,(1280,720),flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I looked at the image 'Straight Lines 1', and found that near the bottom of the image, the lane width is 705 pixels.\n",
    "#This could be used to get the height of the camera from the road\n",
    "\n",
    "#This is simply image distortion such that the source points fit the destination points\n",
    "\n",
    "\n",
    "st_lines_img=cv2.imread('../test_images/straight_lines1.jpg')\n",
    "\n",
    "#for pt in img_pts:\n",
    "#    cv2.circle(st_lines_img,tuple(pt),1,(255,0,0),10)\n",
    "\n",
    "#cv2.imshow('st_lines',st_lines_img)\n",
    "#cv2.waitKey(2000)\n",
    "\n",
    "#ground_pts=np.float32([[0,0],[0,3.6576],[24.384,3.6576],[24.384,0]]) #It seems that the ground points also need to be in pixels\n",
    "\n",
    "warper=ImageWarper()\n",
    "\n",
    "dst=warper.warp_image(st_lines_img)\n",
    "#cv2.imshow('st_lines',dst)\n",
    "#cv2.waitKey(2000)\n",
    "\n",
    "binary_images_directory=glob.glob('../output_images/test*.jpg')\n",
    "canny_images_directory=glob.glob('../output_images/canny/test*.jpg')\n",
    "\n",
    "binary_images=[cv2.imread(img_name) for img_name in binary_images_directory]\n",
    "canny_images=[cv2.imread(img_name) for img_name in canny_images_directory]\n",
    "\n",
    "warped_images_directory='../output_images/warped/'\n",
    "warped_canny_images_directory='../output_images/warped/canny/'\n",
    "\n",
    "for image_no,image in enumerate(binary_images):\n",
    "    dst=warper.warp_image(image)\n",
    "    \n",
    "    canny_image=canny_images[image_no]\n",
    "    dst_canny=warper.warp_image(canny_image)\n",
    "    #cv2.imshow('img',dst)\n",
    "    cv2.imwrite(warped_images_directory+'test'+str(image_no+1)+'.jpg',dst)\n",
    "    cv2.imwrite(warped_canny_images_directory+'test'+str(image_no+1)+'.jpg',dst_canny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Lane Pixels in Warped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the peak of the histogram of white pixels in the bottom half of the image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def histogram(image,top=800,bottom=1250):\n",
    "    #image is assumed to be binary\n",
    "    window_start=0\n",
    "    values=np.sum(image[top:bottom][:],axis=0)\n",
    "    #print(values)\n",
    "    return np.sum(values,axis=1)/3/1000\n",
    "\n",
    "def get_peaks(values,tolerance=5):\n",
    "    peaks=[]\n",
    "    midpoint=int(len(values)/2)\n",
    "    \n",
    "    peaks.append(np.argmax(values[0:midpoint]))\n",
    "    peaks.append(midpoint+np.argmax(values[midpoint:]))\n",
    "    \n",
    "    return peaks #these are pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box:\n",
    "    def __init__(self,image,center_x=30,bottom_y=1250,box_height=120,box_width=120,threshold=500):\n",
    "        self.image=image\n",
    "        \n",
    "        self.bottom_y=bottom_y+box_height\n",
    "        self.center_x=center_x\n",
    "        self.box_width=box_width\n",
    "        self.box_height=box_height\n",
    "        \n",
    "        self.update_coords(self.center_x)\n",
    "        self.points=[(self.center_x,bottom_y)]\n",
    "        self.threshold=threshold #If these many pixels are found, a line exists\n",
    "        \n",
    "        self.search_cutoff=500 #Search for only these amount of pixels\n",
    "        \n",
    "    #Working Fine\n",
    "    def get_mean_x(self):\n",
    "        x_values=0\n",
    "        n_occurences=0\n",
    "        n_iterations=0\n",
    "        \n",
    "        non_zero_x=np.nonzero(self.image[self.top_y:self.bottom_y,self.left:self.right])[1]\n",
    "        \n",
    "        if len(non_zero_x)>self.threshold:\n",
    "            return self.left+int(np.mean(non_zero_x)),True\n",
    "        \n",
    "        return self.center_x,False\n",
    "    \n",
    "    def update_coords(self,center_x):\n",
    "        self.bottom_y-=int(self.box_height)\n",
    "        self.left=max(int(center_x-(self.box_width/2)),0)\n",
    "        self.top_y=max(int(self.bottom_y-self.box_height),0)\n",
    "        self.right=min(self.image.shape[1]-1,int(center_x+self.box_width/2))\n",
    "        \n",
    "        self.center_x=center_x\n",
    "    \n",
    "    def update_points(self):\n",
    "        y=self.bottom_y-int(self.box_height/2)\n",
    "        x,has_line=self.get_mean_x()\n",
    "        \n",
    "        if has_line==False:\n",
    "            x=self.center_x\n",
    "        else:\n",
    "            self.points.append((x,y)) #Only consider boxes that have a line inside\n",
    "        \n",
    "        #import ipdb\n",
    "        #ipdb.set_trace()\n",
    "        self.update_coords(x)\n",
    "        \n",
    "    def get_corners(self):\n",
    "        return [(self.left,self.top_y),(self.right,self.bottom_y)]\n",
    "    \n",
    "class LaneDetector:\n",
    "    def __init__(self,box_width=100,box_height=60,threshold=60,min_interp_points=4):\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.box_width=box_width\n",
    "        self.box_height=box_height\n",
    "                \n",
    "        self.left_points=[]\n",
    "        self.right_points=[]\n",
    "        self.points=[self.left_points,self.right_points]\n",
    "\n",
    "        self.box_locations=[[],[]]\n",
    "        self.polynomial_coeffs=[[],[]]\n",
    "        \n",
    "        self.n_points_interpolation=0\n",
    "        self.min_interp_points=min_interp_points\n",
    "        \n",
    "        self.threshold=threshold\n",
    "        \n",
    "    def set_image(self,image):\n",
    "        self.image=image\n",
    "        \n",
    "        values=histogram(image)\n",
    "        self.peaks=get_peaks(values)\n",
    "        \n",
    "        left_box=Box(image,center_x=self.peaks[0],bottom_y=1250,box_height=self.box_height,box_width=self.box_width,threshold=self.threshold)\n",
    "        right_box=Box(image,center_x=self.peaks[1],bottom_y=1250,box_height=self.box_height,box_width=self.box_width*3//2)\n",
    "        self.boxes=[left_box,right_box]\n",
    "        \n",
    "    def update_points(self):\n",
    "        while(self.boxes[0].top_y>0 and self.boxes[1].top_y>0):\n",
    "            for i,box in enumerate(self.boxes):\n",
    "                self.box_locations[i].append(box.get_corners())\n",
    "                ret=box.update_points()\n",
    "        \n",
    "        #self.left_points=self.boxes[0].points\n",
    "        #self.right_points=self.boxes[1].points\n",
    "        \n",
    "    def draw_rectangles(self):\n",
    "        \n",
    "        for i in range(len(self.box_locations[0])):\n",
    "            left_corners=self.box_locations[0][i]\n",
    "            right_corners=self.box_locations[1][i]\n",
    "            cv2.rectangle(self.image,left_corners[0],left_corners[1],(255,0,0),1)\n",
    "            cv2.rectangle(self.image,right_corners[0],right_corners[1],(0,0,255),1)   \n",
    "    \n",
    "    def fit_points(self):\n",
    "        self.update_points()\n",
    "        for i,box in enumerate(self.boxes):\n",
    "            interp_points=box.points \n",
    "            \n",
    "            if len(interp_points)<self.min_interp_points:\n",
    "                continue\n",
    "            \n",
    "            x=[]\n",
    "            y=[]\n",
    "            for point in interp_points:  #O(img_height/box_height)\n",
    "                x.append(point[0])\n",
    "                y.append(point[1])\n",
    "            self.polynomial_coeffs[i]=np.polyfit(y,x,3) #Choosing cubic polynomials \n",
    "            \n",
    "    def evaluate_polynomial_at(self,y,i):\n",
    "        coeffs=self.polynomial_coeffs[i]\n",
    "        return np.polyval(coeffs,y)\n",
    "    \n",
    "    def constrain(self,value,min_val,max_val):\n",
    "        value=min(value,max_val)\n",
    "        value=max(min_val,value)\n",
    "        return value\n",
    "    \n",
    "    def get_lane_points(self):\n",
    "        points=[]\n",
    "        for y in range(300,1250,2):\n",
    "            top_left=[int(self.evaluate_polynomial_at(y,0)),y]\n",
    "            top_right=[int(self.evaluate_polynomial_at(y,1)),y]\n",
    "            \n",
    "            bottom_left=[int(self.evaluate_polynomial_at(y+1,0)),y+1]\n",
    "            bottom_right=[int(self.evaluate_polynomial_at(y+1,1)),y+1]\n",
    "            \n",
    "            #top_left=self.constrain(left_x,0,719)\n",
    "            #right_x=self.constrain(right_x,0,719)\n",
    "            \n",
    "            points.append([top_left,top_right,bottom_right,bottom_left])\n",
    "            \n",
    "        return np.int32(points)\n",
    "    \n",
    "    def draw_unwarped_lanes(self,frame,warper):\n",
    "        points=self.get_lane_points()\n",
    "        blank_image=np.zeros_like(self.image)\n",
    "        warped_lanes=cv2.fillPoly(blank_image,points,[0,230,0])\n",
    "        \n",
    "        unwarped_lanes=warper.unwarp_image(warped_lanes)\n",
    "        \n",
    "        return cv2.bitwise_or(unwarped_lanes,frame)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LaneDetector' object has no attribute 'boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-d76e3e8cdd16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwarped_images_binary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLaneDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_rectangles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlane_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-4c8ed8ea5027>\u001b[0m in \u001b[0;36mupdate_points\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_y\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_y\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_locations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_corners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LaneDetector' object has no attribute 'boxes'"
     ]
    }
   ],
   "source": [
    "warped_images_directory=glob.glob('../output_images/warped/test*.jpg')\n",
    "warped_images=[cv2.imread(img_name) for img_name in warped_images_directory]\n",
    "\n",
    "warped_images_binary=[cv2.threshold(image,0,255,type=0)[1] for image in warped_images]\n",
    "window_width=50\n",
    "\n",
    "lane_detectors=[]\n",
    "warper=ImageWarper()\n",
    "for image in warped_images_binary: \n",
    "    lane_detector=LaneDetector(image)\n",
    "    lane_detector.update_points()\n",
    "    lane_detector.draw_rectangles()\n",
    "    lane_detector.fit_points()\n",
    "    \n",
    "    #img=lane_detector.draw_unwarped_lanes(frame,warper)\n",
    "    \n",
    "    cv2.imshow('image',lane_detector.image)\n",
    "    cv2.waitKey(2000)\n",
    "    lane_detectors.append(lane_detector)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/calib3d/src/undistort.dispatch.cpp:179: error: (-215:Assertion failed) dst.data != src.data in function 'undistort'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-691deee5da3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Our operations on the frame come here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mbinary_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_binary_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistCoeffs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#This one's undistorted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mbinary_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbinary_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#This converts a one channel image into a 3 channel image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-52887452247e>\u001b[0m in \u001b[0;36mget_binary_image\u001b[0;34m(image, cameraMatrix, distCoeffs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_binary_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistCoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcameraMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdistCoeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#image=cv2.Sobel(image,cv2.CV_64F,1,0,ksize=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/calib3d/src/undistort.dispatch.cpp:179: error: (-215:Assertion failed) dst.data != src.data in function 'undistort'\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('../project_video.mp4')\n",
    "warper=ImageWarper()\n",
    "i=0\n",
    "\n",
    "lane_detector=LaneDetector()\n",
    "while(i<4300):\n",
    "    # Capture frame-by-frame\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC,i*50)\n",
    "    ret, frame = cap.read()\n",
    "    i+=1\n",
    "    #print(i)\n",
    " \n",
    "    # Our operations on the frame come here\n",
    "    binary_image = get_binary_image(frame,cameraMatrix,distCoeffs) #This one's undistorted\n",
    "    binary_image=cv2.merge([binary_image]*3) #This converts a one channel image into a 3 channel image\n",
    "    \n",
    "    warped_image=warper.warp_image(binary_image)\n",
    "    warped_color_image=warper.warp_image(frame)\n",
    "    #ret,warped_image=cv2.threshold(warped_image,0,255,type=0)\n",
    "    \n",
    "    lane_detector.set_image(warped_image)\n",
    "    lane_detector.fit_points()\n",
    "    #lane_detector.draw_rectangles()\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    unwarped_color_image=lane_detector.draw_unwarped_lanes(frame,warper)\n",
    "    cv2.imshow('binary_frame',lane_detector.image[400:,:,:])\n",
    "    cv2.imshow('color_frame',unwarped_color_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0:100,0:100].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('short_image',image[0:400,0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laukik/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/laukik/.local/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
